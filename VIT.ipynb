{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Classification using Vision Transformer\n",
    "\n",
    "In this assignment, I trained and evaluated the Vision Transformer on the Horses vs. Camels dataset.\n",
    "\n",
    "The specific steps for this task are:\n",
    "1. Prepare the dataset (choose any split).\n",
    "2. Build the ViT model.\n",
    "3. Train the model. Record how long it takes.\n",
    "4. Evaluate the performance by reporting the confusion matrix.\n",
    "5. Compared to the CNN that you evaluated on the same dataset in ICA02, explain which model performed better.\n",
    "6. Explain how the Vision Transformer outperform state-of-the-art CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Prepare the dataset\n",
    "\n",
    "Downlaod the dataset from https://www.kaggle.com/datasets/akrsnv/horses-and-camels, save to the same root repro with notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libs\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_addons as tfa\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 360 files belonging to 2 classes.\n",
      "Found 40 files belonging to 2 classes.\n",
      "x_train shape: (32, 32, 32, 3) - y_train shape: (32,)\n",
      "x_test shape: (32, 32, 32, 3) - y_test shape: (32,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-21 01:14:22.179260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [360]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-04-21 01:14:22.179682: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [360]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-21 01:14:22.269933: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [40]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2023-04-21 01:14:22.270193: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [40]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "#prepare the data\n",
    "local_file = os.path.abspath('./archive.zip')\n",
    "path_to_zip = tf.keras.utils.get_file(local_file,'file://'+local_file)\n",
    "PATH = os.path.join(os.path.dirname(path_to_zip), 'archive')\n",
    "train_dir = os.path.join(PATH, 'train')\n",
    "test_dir = os.path.join(PATH, 'test')\n",
    "\n",
    "num_classes = 2\n",
    "BATCH_SIZE = 32\n",
    "input_shape = (32, 32,3)\n",
    "#creat a train_dataset for training by using the keras.utils.image_dataset_from_directory utility.\n",
    "train_dataset = keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=input_shape[:2])\n",
    "#creat a test_dataset for testing by using the keras.utils.image_dataset_from_directory utility.\n",
    "test_dataset = keras.utils.image_dataset_from_directory(test_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=input_shape[:2])\n",
    "\n",
    "x_train, y_train = next(iter(train_dataset))\n",
    "x_test, y_test = next(iter(test_dataset))\n",
    "\n",
    "print(f\"x_train shape: {x_train.shape} - y_train shape: {y_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape} - y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the hyperparameters\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]  # Size of the dense layers of the final classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function PreprocessingLayer.make_adapt_function.<locals>.adapt_step at 0x7fe268620f70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        keras.layers.Normalization(),\n",
    "        keras.layers.Resizing(image_size, image_size),\n",
    "        keras.layers.RandomFlip(\"horizontal\"),\n",
    "        keras.layers.RandomRotation(factor=0.02),\n",
    "        keras.layers.RandomZoom(\n",
    "            height_factor=0.2, width_factor=0.2\n",
    "        ),\n",
    "    ],\n",
    "    name=\"data_augmentation\",\n",
    ")\n",
    "# Compute the mean and the variance of the training data for normalization.\n",
    "data_augmentation.layers[0].adapt(x_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement multilayer perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement multilayer perceptron (MLP)\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "        x = keras.layers.Dropout(dropout_rate)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement patch creation as a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implement patch creation as a layer\n",
    "class Patches(keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display patches for a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: 72 X 72\n",
      "Patch size: 6 X 6\n",
      "Patches per image: 144\n",
      "Elements per patch: 108\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 144 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display patches for a sample image\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_train[np.random.choice(range(x_train.shape[0]))]\n",
    "plt.imshow(image.numpy().astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "resized_image = tf.image.resize(\n",
    "    tf.convert_to_tensor([image]), size=(image_size, image_size)\n",
    ")\n",
    "patches = Patches(patch_size)(resized_image)\n",
    "print(f\"Image size: {image_size} X {image_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
    "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the patch encoding layer\n",
    "The PatchEncoder layer will linearly transform a patch by projecting it into a vector of size projection_dim. In addition, it adds a learnable position embedding to the projected vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = keras.layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Build the ViT model\n",
    "\n",
    "The ViT model consists of multiple Transformer blocks, which use the layers.MultiHeadAttention layer as a self-attention mechanism applied to the sequence of patches. The Transformer blocks produce a [batch_size, num_patches, projection_dim] tensor, which is processed via an classifier head with softmax to produce the final class probabilities output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vit_classifier():\n",
    "    inputs = keras.layers.Input(shape=input_shape)\n",
    "    # Augment data.\n",
    "    augmented = data_augmentation(inputs)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(augmented)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = keras.layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = keras.layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = keras.layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = keras.layers.Flatten()(representation)\n",
    "    representation = keras.layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = keras.layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Train the model. Record how long it takes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the start time of training: 1682057989.21\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - 10s 10s/step - loss: 2.4337 - accuracy: 0.3929 - val_loss: 5.3299 - val_accuracy: 0.2500\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 1s/step - loss: 3.8575 - accuracy: 0.5357 - val_loss: 7.6543 - val_accuracy: 0.7500\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 885ms/step - loss: 14.4962 - accuracy: 0.5714 - val_loss: 1.9567 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 846ms/step - loss: 2.9426 - accuracy: 0.5714 - val_loss: 1.5915 - val_accuracy: 0.5000\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.2156 - accuracy: 0.7143 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 2.4937 - accuracy: 0.6429 - val_loss: 8.0056 - val_accuracy: 0.2500\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 4.7522 - accuracy: 0.5357 - val_loss: 8.0532e-04 - val_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 3.7609 - accuracy: 0.6429 - val_loss: 0.0270 - val_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 2.9877 - accuracy: 0.6429 - val_loss: 6.6624 - val_accuracy: 0.5000\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 4.4726 - accuracy: 0.6429 - val_loss: 1.9901 - val_accuracy: 0.7500\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 2.3924 - accuracy: 0.6429 - val_loss: 0.6900 - val_accuracy: 0.7500\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 6.0576 - accuracy: 0.5714 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 1.6954 - accuracy: 0.7500 - val_loss: 7.9874 - val_accuracy: 0.2500\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 4.5305 - accuracy: 0.6071 - val_loss: 3.6400 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 953ms/step - loss: 2.1501 - accuracy: 0.7500 - val_loss: 1.1579 - val_accuracy: 0.7500\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 968ms/step - loss: 2.0146 - accuracy: 0.7857 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 934ms/step - loss: 2.3752 - accuracy: 0.7500 - val_loss: 0.0411 - val_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 0.3005 - accuracy: 0.8929 - val_loss: 0.4366 - val_accuracy: 0.7500\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 1.2094 - accuracy: 0.7857 - val_loss: 0.8615 - val_accuracy: 0.7500\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 1.6725 - accuracy: 0.6786 - val_loss: 0.0669 - val_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.7912 - accuracy: 0.8571 - val_loss: 1.3508 - val_accuracy: 0.5000\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 1.3217 - accuracy: 0.7857 - val_loss: 0.2069 - val_accuracy: 0.7500\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 2.0227 - accuracy: 0.7143 - val_loss: 0.7716 - val_accuracy: 0.7500\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.1932 - accuracy: 0.8929 - val_loss: 0.3692 - val_accuracy: 0.7500\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.5462 - accuracy: 0.8571 - val_loss: 0.9834 - val_accuracy: 0.7500\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 888ms/step - loss: 0.7791 - accuracy: 0.8214 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 1.3089 - accuracy: 0.7500 - val_loss: 0.1704 - val_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 945ms/step - loss: 1.0678 - accuracy: 0.8929 - val_loss: 2.0736 - val_accuracy: 0.5000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 1.3043 - accuracy: 0.7857 - val_loss: 5.6321 - val_accuracy: 0.5000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 2.6860 - accuracy: 0.8214 - val_loss: 1.4866 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 1.4114 - accuracy: 0.8214 - val_loss: 0.5524 - val_accuracy: 0.7500\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 944ms/step - loss: 1.4679 - accuracy: 0.8571 - val_loss: 0.3263 - val_accuracy: 0.7500\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 930ms/step - loss: 0.2739 - accuracy: 0.9286 - val_loss: 0.4216 - val_accuracy: 0.7500\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.6678 - accuracy: 0.8214 - val_loss: 1.0874 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 2.0256 - accuracy: 0.7500 - val_loss: 0.0396 - val_accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 923ms/step - loss: 0.7389 - accuracy: 0.8571 - val_loss: 5.6624e-04 - val_accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 1.7258 - accuracy: 0.7143 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 915ms/step - loss: 1.7072 - accuracy: 0.7143 - val_loss: 1.3197 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 2.4424 - accuracy: 0.7857 - val_loss: 1.5952 - val_accuracy: 0.5000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 918ms/step - loss: 2.3314 - accuracy: 0.7143 - val_loss: 0.9977 - val_accuracy: 0.7500\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 895ms/step - loss: 2.0093 - accuracy: 0.7857 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 910ms/step - loss: 0.9197 - accuracy: 0.8571 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 907ms/step - loss: 0.9681 - accuracy: 0.7500 - val_loss: 0.7605 - val_accuracy: 0.7500\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.8996 - accuracy: 0.8214 - val_loss: 1.7273 - val_accuracy: 0.5000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 889ms/step - loss: 0.8062 - accuracy: 0.8214 - val_loss: 0.0247 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.5132 - accuracy: 0.8214 - val_loss: 5.7244e-05 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 2.2226 - accuracy: 0.6429 - val_loss: 0.0456 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.5080 - accuracy: 0.9286 - val_loss: 3.0065 - val_accuracy: 0.5000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 2.0498 - accuracy: 0.7500 - val_loss: 1.5177 - val_accuracy: 0.7500\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 932ms/step - loss: 1.4255 - accuracy: 0.9286 - val_loss: 0.0748 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 902ms/step - loss: 2.0373 - accuracy: 0.8571 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 939ms/step - loss: 1.2691 - accuracy: 0.8929 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 919ms/step - loss: 1.7703 - accuracy: 0.8929 - val_loss: 0.7472 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 1.1155 - accuracy: 0.7857 - val_loss: 1.9731 - val_accuracy: 0.7500\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 1.1679 - accuracy: 0.8929 - val_loss: 1.2387 - val_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 909ms/step - loss: 0.9411 - accuracy: 0.8571 - val_loss: 9.6181e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 894ms/step - loss: 1.2644 - accuracy: 0.8214 - val_loss: 9.4098e-05 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 896ms/step - loss: 0.8861 - accuracy: 0.8929 - val_loss: 4.7385e-06 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 916ms/step - loss: 0.0802 - accuracy: 0.9643 - val_loss: 1.4603e-06 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 900ms/step - loss: 1.5451 - accuracy: 0.9286 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.9099 - accuracy: 0.9286 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 908ms/step - loss: 0.5424 - accuracy: 0.8571 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.3893 - accuracy: 0.9286 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 904ms/step - loss: 0.0686 - accuracy: 0.9286 - val_loss: 1.3947e-05 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 906ms/step - loss: 1.1991 - accuracy: 0.9286 - val_loss: 2.8221e-05 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.1926 - accuracy: 0.9643 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 898ms/step - loss: 0.7431 - accuracy: 0.8929 - val_loss: 0.5324 - val_accuracy: 0.7500\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 919ms/step - loss: 0.1964 - accuracy: 0.8929 - val_loss: 1.9001 - val_accuracy: 0.7500\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.7916 - accuracy: 0.8929 - val_loss: 1.4758 - val_accuracy: 0.7500\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 899ms/step - loss: 0.9607 - accuracy: 0.9286 - val_loss: 0.5343 - val_accuracy: 0.7500\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 919ms/step - loss: 0.9796 - accuracy: 0.9286 - val_loss: 8.2004e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 913ms/step - loss: 0.1300 - accuracy: 0.9643 - val_loss: 2.9681e-05 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 0.4187 - accuracy: 0.9286 - val_loss: 2.6524e-06 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 924ms/step - loss: 0.1406 - accuracy: 0.8929 - val_loss: 9.2387e-07 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.9845 - accuracy: 0.7857 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 891ms/step - loss: 0.3503 - accuracy: 0.9643 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 931ms/step - loss: 1.0553 - accuracy: 0.8214 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 941ms/step - loss: 0.3121 - accuracy: 0.9286 - val_loss: 0.2533 - val_accuracy: 0.7500\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.2552 - accuracy: 0.8929 - val_loss: 3.4290 - val_accuracy: 0.7500\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 901ms/step - loss: 1.1576 - accuracy: 0.8571 - val_loss: 3.5569 - val_accuracy: 0.7500\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 0.7972 - accuracy: 0.8214 - val_loss: 0.4432 - val_accuracy: 0.7500\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 912ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.2874 - accuracy: 0.9286 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 917ms/step - loss: 2.0385 - accuracy: 0.8571 - val_loss: 5.9605e-08 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 911ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.1226 - accuracy: 0.9643 - val_loss: 2.7172 - val_accuracy: 0.7500\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 938ms/step - loss: 0.3018 - accuracy: 0.9643 - val_loss: 4.0415 - val_accuracy: 0.7500\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 905ms/step - loss: 0.7594 - accuracy: 0.9286 - val_loss: 2.1332 - val_accuracy: 0.7500\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 936ms/step - loss: 0.4634 - accuracy: 0.9643 - val_loss: 0.1884 - val_accuracy: 0.7500\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 926ms/step - loss: 0.3289 - accuracy: 0.9286 - val_loss: 1.3175e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 893ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.7881e-07 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 935ms/step - loss: 0.6097 - accuracy: 0.9286 - val_loss: 2.9802e-08 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 928ms/step - loss: 0.4617 - accuracy: 0.9643 - val_loss: 8.9407e-08 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 922ms/step - loss: 0.2313 - accuracy: 0.9286 - val_loss: 5.6922e-06 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 921ms/step - loss: 4.2552e-05 - accuracy: 1.0000 - val_loss: 2.1568e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 920ms/step - loss: 1.3186 - accuracy: 0.9286 - val_loss: 1.8626e-05 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 925ms/step - loss: 0.3442 - accuracy: 0.9643 - val_loss: 3.5763e-07 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 914ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 963ms/step - loss: 0.1591 - accuracy: 0.9643 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 903ms/step - loss: 0.1288 - accuracy: 0.9286 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
      "1/1 [==============================] - 0s 259ms/step - loss: 1.3285 - accuracy: 0.7812\n",
      "Test accuracy: 78.12%\n",
      "the end time of training: 1682058093.15 \n",
      "The training time taken: 103.94 seconds\n"
     ]
    }
   ],
   "source": [
    "#Compile, train, and evaluate the mode\n",
    "def run_experiment(model):\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics=[\n",
    "            keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\"),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    checkpoint_filepath = \"/tmp/checkpoint\"\n",
    "    checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "        checkpoint_filepath,\n",
    "        monitor=\"val_accuracy\",\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=num_epochs,\n",
    "        validation_split=0.1,\n",
    "        callbacks=[checkpoint_callback],\n",
    "    )\n",
    "\n",
    "    model.load_weights(checkpoint_filepath)\n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n",
    "\n",
    "    return history\n",
    "\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "print(f\"the start time of training: {start_time:.2f}\")\n",
    "\n",
    "vit_classifier = create_vit_classifier()\n",
    "history = run_experiment(vit_classifier)\n",
    "\n",
    "# End the timer and print the time taken\n",
    "end_time = time.time()\n",
    "print(f\"the end time of training: {end_time:.2f} \")\n",
    "print(f\"The training time taken: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Evaluate the performance by reporting the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe2a4446790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 807ms/step\n",
      "[0 1 0 1 1 0 0 0 0 0 1 0 1 0 1 0 0 1 1 0 1 0 1 0 1 0 1 0 0 1 1 1]\n",
      "[0 1 0 1 1 0 0 0 0 0 1 0 0 0 1 1 0 1 0 1 1 0 0 0 1 1 1 0 0 1 1 0]\n",
      "[[14  4]\n",
      " [ 3 11]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on test set\n",
    "y_pred= vit_classifier.predict(x_test)\n",
    "# Convert predicted values to binary\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "print(y_pred)\n",
    "# Convert y_true tensor to numpy array\n",
    "y_true = y_test.numpy()\n",
    "cm = confusion_matrix(y_true, y_pred,labels=[0,1])\n",
    "print(y_true)\n",
    "# Print confusion matrix\n",
    "print(cm)\n",
    "\n",
    "classes = ['camels','horses']\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('comfusion maxtrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, cm[i, j],\n",
    "    horizontalalignment=\"center\",\n",
    "    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('./vit_confusion_matrix.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Compared to the CNN that you evaluated on the same dataset in ICA02, explain which model performed better.\n",
    "\n",
    "The the model using weight fine-tuning in ICA02 performed better than ViT model on the same dataset. The reason may be due to the dataset only has 2 classes, and the dataset size is not big, only hundrends images. It suggests that the pre-trained weights used for fine-tuning were more appropriate for the this dataset, resulting in better performance. It's possible that the ViT model may perform better on other datasets or under different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Explain how the Vision Transformer outperform state-of-the-art CNNs\n",
    "\n",
    "The Vision Transformer (ViT) has demonstrated state-of-the-art performance on several computer vision tasks, surpassing the performance of convolutional neural networks (CNNs), which have been the go-to architecture for image classification tasks for several years. Here are some reasons why ViT outperforms CNNs:\n",
    "\n",
    "(1) Attention Mechanism: The key difference between ViT and CNNs is the use of the self-attention mechanism. ViT applies the Transformer's self-attention mechanism to images to extract features and create representations. The attention mechanism allows the model to focus on the most relevant parts of the image, enabling it to capture long-range dependencies and relationships between image elements, resulting in more accurate and robust representations.\n",
    "\n",
    "(2) Better Scalability: CNNs rely on convolutional layers, which are designed to capture local features in images. As a result, they are limited in their ability to scale to larger image sizes, and more layers must be added to capture global features effectively. On the other hand, ViT can process the entire image at once, making it more scalable and easier to extend to larger image sizes.\n",
    "\n",
    "(3) Fewer Parameters: Compared to CNNs, ViT requires fewer parameters, which makes it faster to train and more efficient to use. ViT replaces the convolutional layers with self-attention layers, reducing the number of parameters needed to represent the input. This efficiency is particularly important in applications where computational resources are limited.\n",
    "\n",
    "(4) Pre-training: Pre-training with large amounts of unlabeled data is crucial for the performance of deep neural networks. ViT leverages the large-scale pre-training approach used in language modeling, where the model is first trained on a large corpus of text, and then fine-tuned on a downstream task such as image classification. This pre-training enables the model to learn useful and robust features from large amounts of data, improving its ability to generalize to new tasks and datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
